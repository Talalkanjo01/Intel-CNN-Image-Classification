{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":269359,"sourceType":"datasetVersion","datasetId":111880}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Intel Image Classification with CNN\n**Projenin Amacı**\nBu proje Akbank Deep Learning Bootcamp kapsamında hazırlanmıştır.\nAmaç: Intel Image Classification veri setindeki 6 farklı sınıfı (Buildings, Forest, Glacier, Mountain, Sea, Street) CNN tabanlı bir model kullanarak sınıflandırmak.\n\n**Veri Seti**\n* Kaggle Intel Image Classification dataset\n* Train: ~25.000 görüntü\n* Test: ~14.000 görüntü\n* Sınıflar: Buildings, Forest, Glacier, Mountain, Sea, Street\n\n**Yöntem**\n* Veri ön işleme: ImageDataGenerator ile normalizasyon\n* Data Augmentation: rotation, shifting, zoom, horizontal flip\n* CNN mimarisi:\n  * 3 × (Conv2D + MaxPooling) blokları\n  * GlobalAveragePooling2D\n  * Dropout (0.5)\n  * Dense(128, ReLU)\n  * Dense(6, Softmax)\n* Kayıp fonksiyonu: categorical_crossentropy\n* Optimizasyon: Adam\n\n**Sonuçlar**\n* 10 epoch sonunda doğruluk: %75\n* 20 epoch sonunda doğruluk: %82 (daha yüksek ama dalgalı)\n* Accuracy ve Loss grafikleri notebook’ta eklenmiştir.\n\n**Notlar**\n* Model .h5 dosyası olarak kaydedildi.\n* Kaggle Notebook linki teslimde paylaşılacaktır.","metadata":{}},{"cell_type":"markdown","source":"# > Kütüphaneler ve Dataset Yolunu Kontrol","metadata":{}},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-25T22:03:21.217494Z","iopub.execute_input":"2025-09-25T22:03:21.218502Z","iopub.status.idle":"2025-09-25T22:03:21.223605Z","shell.execute_reply.started":"2025-09-25T22:03:21.218475Z","shell.execute_reply":"2025-09-25T22:03:21.222579Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dataset klasörünü kontrol et\nbase_dir = \"../input/intel-image-classification/seg_train/seg_train\"\nprint(\"Klasörler:\", os.listdir(base_dir))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T22:03:23.862980Z","iopub.execute_input":"2025-09-25T22:03:23.863345Z","iopub.status.idle":"2025-09-25T22:03:23.874634Z","shell.execute_reply.started":"2025-09-25T22:03:23.863325Z","shell.execute_reply":"2025-09-25T22:03:23.873710Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# >  Train / Validation Split\n\n## Veri Seti ve Ön İşleme\nProjemizde **Intel Image Classification Dataset** kullanılmıştır.  \nVeri seti 6 sınıftan oluşmaktadır: *Buildings, Forest, Glacier, Mountain, Sea, Street*.  \n\nBu adımda:\n- Veri Kaggle ortamından yüklendi\n- Data Augmentation (çevirme, kaydırma, zoom, horizontal flip) uygulandı\n- Train, validation ve test setleri hazırlandı","metadata":{}},{"cell_type":"code","source":"train_dir = \"../input/intel-image-classification/seg_train/seg_train\"\ntest_dir = \"../input/intel-image-classification/seg_test/seg_test\"\n\n# Validation set için %20 ayıralım\nval_split = 0.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T18:31:01.069450Z","iopub.execute_input":"2025-09-25T18:31:01.069765Z","iopub.status.idle":"2025-09-25T18:31:01.074507Z","shell.execute_reply.started":"2025-09-25T18:31:01.069743Z","shell.execute_reply":"2025-09-25T18:31:01.073612Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# > Data Augmentation ve Generators","metadata":{}},{"cell_type":"code","source":"IMG_SIZE = (150, 150)\nBATCH_SIZE = 32\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=val_split\n)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"categorical\",\n    subset=\"training\"\n)\n\nval_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"categorical\",\n    subset=\"validation\"\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"categorical\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T18:31:04.766238Z","iopub.execute_input":"2025-09-25T18:31:04.766569Z","iopub.status.idle":"2025-09-25T18:31:10.835397Z","shell.execute_reply.started":"2025-09-25T18:31:04.766546Z","shell.execute_reply":"2025-09-25T18:31:10.834620Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# > Örnek Görselleri Çiz\n\n## Örnek Görseller\nAşağıda eğitim setinden seçilen 5 görsel yer almaktadır.  \nBu görseller, modelin üzerinde çalışacağı çeşitliliği göstermektedir.\n","metadata":{}},{"cell_type":"code","source":"sample_images, sample_labels = next(train_generator)\n\nplt.figure(figsize=(20, 4))\nfor i in range(5):  # 5 resim göster\n    plt.subplot(1, 5, i + 1)\n    plt.imshow(sample_images[i])\n    # sınıf indeksinden etiket ismini bul\n    class_names = list(train_generator.class_indices.keys())\n    label_idx = sample_labels[i].argmax()\n    plt.title(class_names[label_idx])\n    plt.axis(\"off\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T18:36:57.052635Z","iopub.execute_input":"2025-09-25T18:36:57.052955Z","iopub.status.idle":"2025-09-25T18:36:58.008929Z","shell.execute_reply.started":"2025-09-25T18:36:57.052933Z","shell.execute_reply":"2025-09-25T18:36:58.008092Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# > CNN Modeli \n\n## CNN Modeli\nBu projede temel bir Convolutional Neural Network (CNN) kullanılmıştır.  \nModel yapısı:\n- 3 adet Conv2D + MaxPooling katmanı\n- GlobalAveragePooling2D\n- Dropout (%50)\n- Dense(128, ReLU)\n- Dense(6, Softmax)\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers, models\n\nIMG_SIZE = (150, 150, 3)\nNUM_CLASSES = 6  # buildings, forest, glacier, mountain, sea, street\n\nmodel = models.Sequential([\n    layers.Conv2D(32, (3,3), activation='relu', input_shape=IMG_SIZE),\n    layers.MaxPooling2D(2,2),\n\n    layers.Conv2D(64, (3,3), activation='relu'),\n    layers.MaxPooling2D(2,2),\n\n    layers.Conv2D(128, (3,3), activation='relu'),\n    layers.MaxPooling2D(2,2),\n\n    layers.GlobalAveragePooling2D(),  # Flatten yerine daha verimli\n    layers.Dropout(0.5),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(NUM_CLASSES, activation='softmax')  # multi-class çıkış\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T18:39:16.027044Z","iopub.execute_input":"2025-09-25T18:39:16.027719Z","iopub.status.idle":"2025-09-25T18:39:16.166975Z","shell.execute_reply.started":"2025-09-25T18:39:16.027691Z","shell.execute_reply":"2025-09-25T18:39:16.166266Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# > Modeli Eğit \n\n## Eğitim Sonuçları\nAşağıda train ve validation accuracy/loss grafikleri yer almaktadır.  \n10 epoch ile %75 doğruluk, 20 epoch ile %82 doğruluk elde edilmiştir.\n","metadata":{}},{"cell_type":"code","source":"EPOCHS = 20\n\nhistory = model.fit(\n    train_generator,\n    epochs=EPOCHS,\n    validation_data=val_generator\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T19:46:57.117593Z","iopub.execute_input":"2025-09-25T19:46:57.117940Z","iopub.status.idle":"2025-09-25T21:29:29.466521Z","shell.execute_reply.started":"2025-09-25T19:46:57.117914Z","shell.execute_reply":"2025-09-25T21:29:29.465507Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# > Accuracy ve Loss Grafikleri ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,4))\n\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'], label='Train Acc')\nplt.plot(history.history['val_accuracy'], label='Val Acc')\nplt.title('Accuracy')\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Val Loss')\nplt.title('Loss')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:29:29.846308Z","iopub.execute_input":"2025-09-25T21:29:29.846622Z","iopub.status.idle":"2025-09-25T21:29:30.211084Z","shell.execute_reply.started":"2025-09-25T21:29:29.846596Z","shell.execute_reply":"2025-09-25T21:29:30.210157Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# > Confusion Matrix & Classification Report ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\n# Test set üzerinden tahmin yap\ny_pred = model.predict(test_generator)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true = test_generator.classes\n\n# Sınıf isimlerini al\nclass_labels = list(test_generator.class_indices.keys())\n\n# Confusion Matrix\ncm = confusion_matrix(y_true, y_pred_classes)\n\nplt.figure(figsize=(8,6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()\n\n# Classification Report\nprint(\"Classification Report:\")\nprint(classification_report(y_true, y_pred_classes, target_names=class_labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T22:04:44.999909Z","iopub.execute_input":"2025-09-25T22:04:45.000345Z","iopub.status.idle":"2025-09-25T22:05:09.347176Z","shell.execute_reply.started":"2025-09-25T22:04:45.000319Z","shell.execute_reply":"2025-09-25T22:05:09.346273Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# > Eigen-CAM Görselleştirmesi ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing import image\nfrom sklearn.decomposition import PCA\n\ndef make_eigencam_heatmap(img_array, model, last_conv_layer_name):\n    # Son convolutional layer'dan feature map al\n    feature_model = tf.keras.models.Model(\n        inputs=model.inputs,\n        outputs=model.get_layer(last_conv_layer_name).output\n    )\n    feature_maps = feature_model.predict(img_array)[0]  # shape: (H, W, Channels)\n\n    # Feature mapleri (H*W, Channels) haline getir\n    reshaped = feature_maps.reshape((-1, feature_maps.shape[-1]))\n\n    # PCA ile 1. principal component → Eigen-CAM\n    pca = PCA(n_components=1)\n    pca.fit(reshaped)\n    eigencam = reshaped @ pca.components_[0]\n    eigencam = eigencam.reshape((feature_maps.shape[0], feature_maps.shape[1]))\n\n    # Normalize et\n    eigencam = (eigencam - eigencam.min()) / (eigencam.max() - eigencam.min())\n    return eigencam\n\n# ---- Örnek Görsel ----\nsample_img_path = test_generator.filepaths[25]  # istediğin index seç\nimg = image.load_img(sample_img_path, target_size=IMG_SIZE[:2])\nimg_array = image.img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0) / 255.0\n\n# Eigen-CAM heatmap üret\nheatmap = make_eigencam_heatmap(img_array, model, \"conv2d_2\")\n\n# Orijinal resim\nimg = cv2.imread(sample_img_path)\nimg = cv2.resize(img, IMG_SIZE[:2])\n\n# Heatmap bindir\nheatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\nheatmap = np.uint8(255 * heatmap)\nheatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\noverlay = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)\n\n# Çizdir\nplt.figure(figsize=(12,4))\nplt.subplot(1,3,1); plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)); plt.title(\"Original\")\nplt.subplot(1,3,2); plt.imshow(heatmap, cmap=\"jet\"); plt.title(\"Eigen-CAM Heatmap\")\nplt.subplot(1,3,3); plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)); plt.title(\"Overlay\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T22:11:39.581761Z","iopub.execute_input":"2025-09-25T22:11:39.582582Z","iopub.status.idle":"2025-09-25T22:11:40.741018Z","shell.execute_reply.started":"2025-09-25T22:11:39.582554Z","shell.execute_reply":"2025-09-25T22:11:40.740093Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modelin Dikkat Mekanizması – Eigen-CAM\nModelin sınıflandırma sırasında görsellerin hangi bölgelerine odaklandığını incelemek için Eigen-CAM yöntemi uygulanmıştır.\n\nAşağıdaki örnekte görüldüğü üzere:\n* Model, bina görsellerinde özellikle alt kısımlar ve kenar çizgilerine odaklanmaktadır.\n* Bu da CNN’in sınıflandırmayı yaparken rastgele piksellere değil, yapısal detaylara dayandığını göstermektedir.","metadata":{}},{"cell_type":"markdown","source":"# Hiperparametre Optimizasyonu\nModelin doğruluk performansını iyileştirmek amacıyla bazı hiperparametreler üzerinde denemeler yapılmıştır.\n\n* Learning rate 0.001 → Val. Accuracy: %82\n* Learning rate 0.0005 → Val. Accuracy: %80 (daha stabil ama daha düşük)\n* Batch size 32 → daha hızlı convergence\n* Batch size 64 → eğitim süresi daha uzun, doğrulukta anlamlı fark yok\n\nSonuç olarak, batch size=32 ve learning rate=0.001 en iyi kombinasyon olarak seçilmiştir.","metadata":{}},{"cell_type":"markdown","source":"# > Learning Rate Denemeleri","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import optimizers\n\ndef build_model(lr=0.001):\n    model = models.Sequential([\n        layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n        layers.MaxPooling2D(2,2),\n\n        layers.Conv2D(64, (3,3), activation='relu'),\n        layers.MaxPooling2D(2,2),\n\n        layers.Conv2D(128, (3,3), activation='relu'),\n        layers.MaxPooling2D(2,2),\n\n        layers.GlobalAveragePooling2D(),\n        layers.Dropout(0.5),\n        layers.Dense(128, activation='relu'),\n        layers.Dense(6, activation='softmax')\n    ])\n    \n    opt = optimizers.Adam(learning_rate=lr)\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n# Deneme 1: lr = 0.001\nmodel1 = build_model(lr=0.001)\nhistory1 = model1.fit(train_generator, epochs=5, validation_data=val_generator, verbose=1)\n\n# Deneme 2: lr = 0.0005\nmodel2 = build_model(lr=0.0005)\nhistory2 = model2.fit(train_generator, epochs=5, validation_data=val_generator, verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T22:19:21.426920Z","iopub.execute_input":"2025-09-25T22:19:21.427300Z","iopub.status.idle":"2025-09-25T23:11:47.162742Z","shell.execute_reply.started":"2025-09-25T22:19:21.427277Z","shell.execute_reply":"2025-09-25T23:11:47.161869Z"}},"outputs":[],"execution_count":null}]}